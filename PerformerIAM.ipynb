{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PerformerIAM.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyM7NXYLsX2ysg97EqKrvPI6",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vijjus/CV/blob/master/PerformerIAM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zQW4svS5x2zJ",
        "outputId": "0fb4660f-912e-4d15-c64a-822abf029c16"
      },
      "source": [
        "!uname -a"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Linux 40e2ae908d75 5.4.109+ #1 SMP Tue Apr 20 19:55:43 PDT 2021 x86_64 x86_64 x86_64 GNU/Linux\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3EKLRZzgOb5R",
        "outputId": "28271791-d5b5-410c-d45f-89345a8102e1"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mon May 10 21:14:22 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 465.19.01    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla V100-SXM2...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   33C    P0    25W / 300W |      0MiB / 16160MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WKlUHR5AOeI5",
        "outputId": "c2362cbb-b454-4a41-95e6-6c197d33a912"
      },
      "source": [
        "!pip install performer-pytorch"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting performer-pytorch\n",
            "  Downloading https://files.pythonhosted.org/packages/ff/98/93f4d70d519276f075826155b0f7367ba9d50ea36cbed2dfec91f5e66c7d/performer_pytorch-1.0.11-py3-none-any.whl\n",
            "Collecting axial-positional-embedding>=0.1.0\n",
            "  Downloading https://files.pythonhosted.org/packages/7a/27/ad886f872b15153905d957a70670efe7521a07c70d324ff224f998e52492/axial_positional_embedding-0.2.1.tar.gz\n",
            "Collecting local-attention>=1.1.1\n",
            "  Downloading https://files.pythonhosted.org/packages/44/55/140bd9670e1a64380162f49535a43af8ddb6e7fe61eb0983633bcd0c8294/local_attention-1.4.1-py3-none-any.whl\n",
            "Requirement already satisfied: torch>=1.6 in /usr/local/lib/python3.7/dist-packages (from performer-pytorch) (1.8.1+cu101)\n",
            "Collecting einops>=0.3\n",
            "  Downloading https://files.pythonhosted.org/packages/5d/a0/9935e030634bf60ecd572c775f64ace82ceddf2f504a5fd3902438f07090/einops-0.3.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch>=1.6->performer-pytorch) (1.19.5)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.6->performer-pytorch) (3.7.4.3)\n",
            "Building wheels for collected packages: axial-positional-embedding\n",
            "  Building wheel for axial-positional-embedding (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for axial-positional-embedding: filename=axial_positional_embedding-0.2.1-cp37-none-any.whl size=2905 sha256=019c984902b25f323fd559c77770a3da71af454c4e0e5502f23fb95d9a8d9573\n",
            "  Stored in directory: /root/.cache/pip/wheels/cd/f8/93/25b60e319a481e8f324dcb1871aff818eb0c8143ed20b732b4\n",
            "Successfully built axial-positional-embedding\n",
            "Installing collected packages: axial-positional-embedding, local-attention, einops, performer-pytorch\n",
            "Successfully installed axial-positional-embedding-0.2.1 einops-0.3.0 local-attention-1.4.1 performer-pytorch-1.0.11\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z3ys0nnqf62h",
        "outputId": "815a5f5b-875e-41c8-93be-aceafb5b1caf"
      },
      "source": [
        "!pip install vit-pytorch"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting vit-pytorch\n",
            "  Downloading https://files.pythonhosted.org/packages/a1/5b/29cfe1b97d86094b70ab3c3812a0ad87e19c6e20cf3cb9b5aec82000e7ea/vit_pytorch-0.18.3-py3-none-any.whl\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (from vit-pytorch) (0.9.1+cu101)\n",
            "Requirement already satisfied: torch>=1.6 in /usr/local/lib/python3.7/dist-packages (from vit-pytorch) (1.8.1+cu101)\n",
            "Requirement already satisfied: einops>=0.3 in /usr/local/lib/python3.7/dist-packages (from vit-pytorch) (0.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchvision->vit-pytorch) (1.19.5)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.7/dist-packages (from torchvision->vit-pytorch) (7.1.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.6->vit-pytorch) (3.7.4.3)\n",
            "Installing collected packages: vit-pytorch\n",
            "Successfully installed vit-pytorch-0.18.3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ttBJGD8xN82A",
        "outputId": "87007021-5fa6-4725-fef4-3f0f8f8a0f84"
      },
      "source": [
        "!pip install colorama"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting colorama\n",
            "  Downloading https://files.pythonhosted.org/packages/44/98/5b86278fbbf250d239ae0ecb724f8572af1c91f4a11edf4d36a206189440/colorama-0.4.4-py2.py3-none-any.whl\n",
            "Installing collected packages: colorama\n",
            "Successfully installed colorama-0.4.4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G-UJh4kEOuD6"
      },
      "source": [
        "import os\n",
        "import cv2\n",
        "import sys\n",
        "import random\n",
        "import torch\n",
        "import collections\n",
        "import editdistance\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "import torch.nn as nn\n",
        "from colorama import Fore\n",
        "from itertools import groupby\n",
        "import albumentations as A\n",
        "import torch.nn.functional as F\n",
        "from google.colab import drive\n",
        "import matplotlib.pyplot as plt\n",
        "from vit_pytorch.vit import PreNorm, Attention, Transformer\n",
        "from performer_pytorch import Performer\n",
        "from albumentations.pytorch import ToTensor"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gvFJfP3wo-jP",
        "outputId": "d405c530-8911-4f15-db05-90271817bbca"
      },
      "source": [
        "drive.mount(\"/content/gdrive\")"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lfKe_nVApCt5",
        "outputId": "547e0097-57f8-4b06-8bfe-b27d4cecad46"
      },
      "source": [
        "!ls /content/gdrive/MyDrive/IAM-lines.tgz"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gdrive/MyDrive/IAM-lines.tgz\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FQJElXkrpY0K"
      },
      "source": [
        "!cp  /content/gdrive/MyDrive/IAM-lines.tgz ."
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8YHQQ-kXpsKA"
      },
      "source": [
        "!rm -rf data; mkdir data; mv IAM-lines.tgz data/"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HsTXlJfhp1ip",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3aae6699-1564-40a8-e99f-1c9d6c0a10db"
      },
      "source": [
        "!cd data; tar -zxf IAM-lines.tgz; cd -"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4R-afhH5BTjl",
        "outputId": "b83d1665-9c12-4afa-c972-5a5df2857c1b"
      },
      "source": [
        "!tail -10 data/lines/lines.txt.test"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "r06-103-05 err 185 17 351 1630 1601 137 confessed|everything|.|Her|fiance*?2\n",
            "r06-106-00 ok 185 16 340 731 1650 141 The|day|I|promised|to|take|Catherine\n",
            "r06-106-01 ok 184 21 342 915 1718 136 down|to|visit|my|young|friend|Philip\n",
            "r06-106-08 ok 182 18 351 2172 1816 132 Renoir|girl|who|expects|everything|from\n",
            "r06-111-05 ok 181 16 347 1645 1765 113 romantic|than|large|houses|.|We|drank\n",
            "r06-111-08 ok 182 13 354 2167 1173 131 thing|from|food|to|music|.\n",
            "r06-115-04 err 185 20 370 1444 1743 143 I|suggested|she|might|find|them|dif-\n",
            "r06-115-09 ok 183 14 351 2359 1793 115 pages|of|Babel|,|for|she|was|determined\n",
            "r06-121-04 ok 184 13 336 1451 1642 138 their|bright|friendly|heads|turned\n",
            "r06-121-10 ok 183 16 353 2530 1769 117 the|pictures|just|for|the|fun|of|it|was\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ymzlT8nRDU0F"
      },
      "source": [
        "def list_files_and_basename_recursive(dirpath, ext):\n",
        "    # TODO unit test\n",
        "    retlist = {}\n",
        "    for root, dirs, files in os.walk(dirpath):\n",
        "        for filename in files:\n",
        "            if not filename.endswith(ext):\n",
        "                continue\n",
        "\n",
        "            image_filename_no_ext = os.path.basename(os.path.splitext(filename)[0])\n",
        "            retlist[image_filename_no_ext] = os.path.join(root, filename)\n",
        "\n",
        "    return retlist"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Bz9HBpqHsHm"
      },
      "source": [
        "from PIL import Image\n",
        "from torch.utils.data.dataloader import default_collate\n",
        "from typing import Callable, Dict, List, Set"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "la5DMGTnIb1S"
      },
      "source": [
        "class Vocabulary(object):\n",
        "    \"\"\"Convert between str and label.\n",
        "    NOTE:\n",
        "        Insert `blank` to the alphabet for CTC.\n",
        "    Args:\n",
        "        alphabet (Iterable): set of the possible characters.\n",
        "        ignore_case (bool, default=False): whether or not to ignore all of the case.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, alphabet: List):\n",
        "        self.alphabet = alphabet\n",
        "\n",
        "        self.dict = {}\n",
        "        for i, char in enumerate(alphabet):\n",
        "            self.dict[char] = i\n",
        "\n",
        "    @property\n",
        "    def num_classes(self):\n",
        "        return len(self.dict)\n",
        "\n",
        "    def encode(self, text):\n",
        "        \"\"\"Support batch or single str.\n",
        "        Args:\n",
        "            text (str or list of str): texts to convert.\n",
        "        Returns:\n",
        "            torch.IntTensor [length_0 + length_1 + ... length_{n - 1}]: encoded texts.\n",
        "            torch.IntTensor [n]: length of each text.\n",
        "        \"\"\"\n",
        "        if isinstance(text, str):\n",
        "            text = [self.dict[char] for char in text]\n",
        "            length = [len(text)]\n",
        "        elif isinstance(text, torch.Tensor):\n",
        "            if text.dim() == 2:\n",
        "                label = []\n",
        "                length = []\n",
        "                for sub in text:\n",
        "                    label_char = [self.dict[str(x)] for x in sub.tolist()]\n",
        "                    label.append(label_char)\n",
        "                    length.append(len(sub))\n",
        "                text = label\n",
        "            else:\n",
        "                text = [self.dict[str(x)] for x in text.tolist()]\n",
        "                length = [len(text)]\n",
        "        elif isinstance(text, collections.Iterable):\n",
        "            length = [len(s) for s in text]\n",
        "            text = \"\".join(text)\n",
        "            text, _ = self.encode(text)\n",
        "        else:\n",
        "            raise ValueError(f\"Invalid input type {type(text)}\")\n",
        "\n",
        "        return torch.IntTensor(text), torch.IntTensor(length)\n",
        "\n",
        "    def decode(self, t, length, raw=False):\n",
        "        \"\"\"Decode encoded texts back into strs.\n",
        "        Args:\n",
        "            torch.IntTensor [length_0 + length_1 + ... length_{n - 1}]: encoded texts.\n",
        "            torch.IntTensor [n]: length of each text.\n",
        "        Raises:\n",
        "            AssertionError: when the texts and its length does not match.\n",
        "        Returns:\n",
        "            text (str or list of str): texts to convert.\n",
        "        \"\"\"\n",
        "        if length.numel() == 1:\n",
        "            length = length[0]\n",
        "            assert (\n",
        "                t.numel() == length\n",
        "            ), \"text with length: {} does not match declared length: {}\".format(\n",
        "                t.numel(), length\n",
        "            )\n",
        "            if raw:\n",
        "                return \"\".join(\n",
        "                    [self.alphabet[i] if self.alphabet[i] != \"<SEP>\" else \"\" for i in t]\n",
        "                )\n",
        "            else:\n",
        "                char_list = []\n",
        "                for i in range(length):\n",
        "                    if t[i] != 0 and (not (i > 0 and t[i - 1] == t[i])):\n",
        "                        c = self.alphabet[t[i]]\n",
        "                        if c == \"<SEP>\":\n",
        "                            c = \" \"\n",
        "                        char_list.append(c)\n",
        "                return \"\".join(char_list)\n",
        "        else:\n",
        "            # batch mode\n",
        "            assert (\n",
        "                t.numel() == length.sum()\n",
        "            ), \"texts with length: {} does not match declared length: {}\".format(\n",
        "                t.numel(), length.sum()\n",
        "            )\n",
        "            texts = []\n",
        "            index = 0\n",
        "            for i in range(length.numel()):\n",
        "                label_length = length[i]\n",
        "                texts.append(\n",
        "                    self.decode(\n",
        "                        t[index : index + label_length],\n",
        "                        torch.IntTensor([label_length]),\n",
        "                        raw=raw,\n",
        "                    )\n",
        "                )\n",
        "                index += label_length\n",
        "            return texts\n"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "irMWm89EQVQb"
      },
      "source": [
        "def base_collator_with_padding(\n",
        "    pad_key, base_collator_fn=default_collate, pad_val=0, pad_idx=0\n",
        "):\n",
        "    \"\"\"Pad: a given key in the data iterator output to a consistent length.\n",
        "    Otherwise, falls back to default collate functionality\n",
        "    Args:\n",
        "        pad_key: str The specific data stream to pad\n",
        "        base_collator_fn: Callable The default collator to call. Defaults to default_collate from PyTorch\n",
        "        pad_val: Any The value to pad in the tensor. Defaults to 0\n",
        "    Returns:\n",
        "        The result of collation, including padding of the variable length streams\n",
        "    \"\"\"\n",
        "\n",
        "    def fn(batch):\n",
        "        max_len = max(item[pad_key].shape[pad_idx] for item in batch)\n",
        "\n",
        "        for item in batch:\n",
        "            original_tensor = item[pad_key]\n",
        "\n",
        "            # TODO currently assumes a single dimension tensor\n",
        "            padded_tensor = torch.full((max_len,), pad_val, dtype=original_tensor.dtype)\n",
        "            padded_tensor[: original_tensor.shape[pad_idx]] = original_tensor\n",
        "\n",
        "            item[pad_key] = padded_tensor\n",
        "\n",
        "        return base_collator_fn(batch)\n",
        "\n",
        "    return fn\n"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y7XwxI7XDOk9"
      },
      "source": [
        "class IAMLinesDataset(torch.utils.data.Dataset):\n",
        "    LINE_LEVEL_FIELDNAMES = [\n",
        "        \"line_id\",\n",
        "        \"line_segmentation_result\",\n",
        "        \"graylevel\",\n",
        "        \"components\",\n",
        "        \"bbox_x\",\n",
        "        \"bbox_y\",\n",
        "        \"bbox_w\",\n",
        "        \"bbox_h\",\n",
        "        \"label\",\n",
        "    ]\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        image_directory: str,\n",
        "        lines_file: str,\n",
        "        image_extension: str = \"png\",\n",
        "        transform: Callable = None,\n",
        "        max_sequence_len=None,\n",
        "    ):\n",
        "        self._data = []\n",
        "        self._transform = transform\n",
        "\n",
        "        image_filepaths = list_files_and_basename_recursive(\n",
        "            image_directory, image_extension\n",
        "        )\n",
        "\n",
        "        chars: Set[str] = set()\n",
        "\n",
        "        self._limit_max_sequence_length = bool(max_sequence_len)\n",
        "\n",
        "        # either set it to our upper limit, or initialize it to be overridden by our longest sequence\n",
        "        self._max_sequence_length = (\n",
        "            max_sequence_len if self._limit_max_sequence_length else -1\n",
        "        )\n",
        "\n",
        "        with open(lines_file) as fp:\n",
        "            # QUOTE_NONE is required here, there are some open double quotes in the file that screw with parsing\n",
        "            reader = csv.DictReader(\n",
        "                fp,\n",
        "                fieldnames=self.LINE_LEVEL_FIELDNAMES,\n",
        "                delimiter=\" \",\n",
        "                quoting=csv.QUOTE_NONE,\n",
        "            )\n",
        "            for row in reader:\n",
        "                data_dict = {\n",
        "                    \"image_filepath\": image_filepaths[row[\"line_id\"]],\n",
        "                }\n",
        "\n",
        "                label_str = row[\"label\"]\n",
        "                label_str = label_str.replace(\"|\", \" \")\n",
        "                label_len = len(label_str)\n",
        "                if self._limit_max_sequence_length:\n",
        "                    label_str = label_str[: self._max_sequence_length]\n",
        "                    new_label_len = len(label_str)\n",
        "                    if label_len != new_label_len:\n",
        "                        warnings.warn(\n",
        "                            f\"Had to truncate image label {row['word_id']}, label string too long \"\n",
        "                            f\"(was {label_len}, limit {self._max_sequence_length})\"\n",
        "                        )\n",
        "\n",
        "                elif label_len > self._max_sequence_length:\n",
        "                    self._max_sequence_length = label_len\n",
        "\n",
        "                chars.update(label_str)\n",
        "\n",
        "                data_dict[\"label\"] = label_str\n",
        "                self._data.append(data_dict)\n",
        "\n",
        "        # Could be an issue if the train set doesn't have some symbols.\n",
        "\n",
        "        # NOTE index 0 is our blank space index\n",
        "        self.vocab = Vocabulary([\"<SEP>\"] + sorted(chars))\n",
        "\n",
        "    # TODO num_classes and max_seq_len should be precalculated\n",
        "    @property\n",
        "    def num_classes(self):\n",
        "        return self.vocab.num_classes\n",
        "\n",
        "    @property\n",
        "    def max_sequence_len(self):\n",
        "        return self._max_sequence_length\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self._data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        data_at_idx = self._data[idx]\n",
        "        image_filepath = data_at_idx[\"image_filepath\"]\n",
        "        image_label = data_at_idx[\"label\"]\n",
        "\n",
        "        image = cv2.imread(image_filepath, cv2.IMREAD_GRAYSCALE)\n",
        "        image = cv2.resize(image, (500, 50), cv2.INTER_AREA)\n",
        "\n",
        "        # invert the image\n",
        "        image = image.max() - image\n",
        "        if self._transform:\n",
        "            image = self._transform(image=image)['image']\n",
        "            image = image.permute(1, 0)\n",
        "\n",
        "        label_indices, label_length = self.vocab.encode(image_label)\n",
        "\n",
        "        return {\n",
        "            \"image\": image,\n",
        "            \"label_indices\": label_indices,\n",
        "            \"label_length\": label_length,\n",
        "            \"label_str\": image_label,\n",
        "        }"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gZh_uCiHITDr"
      },
      "source": [
        "import csv"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rRrQR5yXEruQ"
      },
      "source": [
        "train_transform = A.Compose([\n",
        "    #A.ShiftScaleRotate(shift_limit=0, scale_limit=0, rotate_limit=3, p=0.5),\n",
        "    #A.OpticalDistortion(p=0.5),\n",
        "    A.Normalize(mean=[0.5], std=[0.5]),\n",
        "    ToTensor(),\n",
        "])"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wqE7wTIRHusH"
      },
      "source": [
        "MAX_SEQ_LEN = 93\n",
        "trainset = IAMLinesDataset(\n",
        "    '/content/data/lines',\n",
        "    '/content/data/lines/lines.txt.train',\n",
        "    transform=train_transform,\n",
        "    max_sequence_len=MAX_SEQ_LEN,\n",
        ")"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uMnvZUbWIe9a"
      },
      "source": [
        "train_iter = iter(trainset)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aMD-uTeuIjJ7"
      },
      "source": [
        "data = next(train_iter)"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uVm3uFOMImMB",
        "outputId": "c6c2bb97-e27c-4541-a9d4-41d8247f9d59"
      },
      "source": [
        "data"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'image': tensor([[-1., -1., -1.,  ..., -1., -1., -1.],\n",
              "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
              "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
              "         ...,\n",
              "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
              "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
              "         [-1., -1., -1.,  ..., -1., -1., -1.]]),\n",
              " 'label_indices': tensor([28,  1, 40, 42, 49, 32,  1, 73, 68,  1, 72, 73, 68, 69,  1, 40, 71, 13,\n",
              "          1, 34, 54, 62, 73, 72, 64, 58, 65, 65,  1, 59, 71, 68, 66],\n",
              "        dtype=torch.int32),\n",
              " 'label_length': tensor([33], dtype=torch.int32),\n",
              " 'label_str': 'A MOVE to stop Mr. Gaitskell from'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NOW_CqBsI31j",
        "outputId": "84919fde-43b7-44f6-be2d-130dbc4ffcba"
      },
      "source": [
        "data['image'].shape"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([50, 500])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "Gi8mIxZUKk1j",
        "outputId": "b64ea483-82f4-460f-a53a-6612a0a58494"
      },
      "source": [
        "data['label_str']"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'A MOVE to stop Mr. Gaitskell from'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "id": "2i5ezp0SI8Hz",
        "outputId": "55b21faf-e721-42ec-be23-d3feb28498e8"
      },
      "source": [
        "plt.imshow(data['image'], cmap='gray')"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f8b98b8ae90>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AUl8mDUsDr4R"
      },
      "source": [
        "val_transform = A.Compose([\n",
        "    A.Normalize(mean=[0.5], std=[0.5]),\n",
        "    ToTensor(),\n",
        "])"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lqnfdqVHLsmw"
      },
      "source": [
        "testset = IAMLinesDataset(\n",
        "    '/content/data/lines',\n",
        "    '/content/data/lines/lines.txt.test',\n",
        "    transform=val_transform,\n",
        "    max_sequence_len=MAX_SEQ_LEN,\n",
        ")"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pTQXH063stQD",
        "outputId": "4f8cde46-eafc-4348-ffa3-896034ac428d"
      },
      "source": [
        "max_h=0\n",
        "max_w=0\n",
        "max_l=0\n",
        "vocab = set()\n",
        "for data in trainset:\n",
        "  img = data['image']\n",
        "  max_w = max(max_w, img.shape[1])\n",
        "  max_h = max(max_h, img.shape[0])\n",
        "  text = data['label_str']\n",
        "  max_l = max(max_l, len(text))\n",
        "  for c in text:\n",
        "    if c not in vocab:\n",
        "      vocab.add(c)\n",
        "print(f'Max height={max_h}, width={max_w}, label={max_l}')\n",
        "vocab = list(vocab)\n",
        "vocab.sort()\n",
        "print(''.join(vocab))"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Max height=50, width=500, label=93\n",
            " !\"#&'()*+,-./0123456789:;?ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GpdAZRoTLfM-",
        "outputId": "a5e2e691-3457-4a3a-f251-c5b65c5aabcb"
      },
      "source": [
        "len(vocab)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "79"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7vtdznNJYz-z"
      },
      "source": [
        "def count_parameters(model):\n",
        "    params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "    return params / 1000000"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "enMsBoK8iAv-"
      },
      "source": [
        "from torch import nn, einsum\n",
        "import torch.nn.functional as F\n",
        "from einops import rearrange, repeat\n",
        "from torch.nn import Conv2d, Dropout, LogSoftmax\n",
        "from einops.layers.torch import Rearrange"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "scpvUnSwhgFC"
      },
      "source": [
        "def pair(t):\n",
        "    return t if isinstance(t, tuple) else (t, t)\n",
        "class ViT(nn.Module):\n",
        "    def __init__(self, *, image_size, patch_size, num_classes, dim, \n",
        "                 depth, heads, mlp_dim, pool = 'mean', channels = 3, \n",
        "                 dim_head = 64, dropout = 0., emb_dropout = 0.,\n",
        "                 patch_method = \"linear\", transformer='regular'):\n",
        "        super().__init__()\n",
        "        image_height, image_width = pair(image_size)\n",
        "        patch_height, patch_width = pair(patch_size)\n",
        "\n",
        "        assert image_height % patch_height == 0 and image_width % patch_width == 0, 'Image dimensions must be divisible by the patch size.'\n",
        "\n",
        "        num_patches = (image_height // patch_height) * (image_width // patch_width)\n",
        "        patch_dim = channels * patch_height * patch_width\n",
        "        assert pool in {'cls', 'mean'}, 'pool type must be either cls (cls token) or mean (mean pooling)'\n",
        "\n",
        "        if patch_method == \"linear\":\n",
        "          self.to_patch_embedding = nn.Sequential(\n",
        "            Rearrange('b c (h p1) (w p2) -> b (h w) (p1 p2 c)', p1 = patch_height, p2 = patch_width),\n",
        "            nn.Linear(patch_dim, dim),\n",
        "          )\n",
        "        else:\n",
        "          self.to_patch_embedding = nn.Conv2d(\n",
        "            in_channels=channels,\n",
        "            out_channels=dim,\n",
        "            kernel_size=patch_size,\n",
        "            stride=patch_size,\n",
        "          )\n",
        "\n",
        "        self.pos_embedding = nn.Parameter(torch.randn(1, num_patches + 1, dim))\n",
        "        self.dropout = nn.Dropout(emb_dropout)\n",
        "\n",
        "        if transformer == 'performer':\n",
        "          self.transformer = Performer(dim=dim, depth=depth, \n",
        "                                       heads=heads, dim_head=dim_head,\n",
        "                                       attn_dropout=dropout,\n",
        "                                       causal=True)\n",
        "        else:\n",
        "          self.transformer = Transformer(dim, depth, heads, dim_head, mlp_dim, dropout)\n",
        "\n",
        "        self.pool = pool\n",
        "        self.to_latent = nn.Identity()\n",
        "\n",
        "        self.mlp_head = nn.Sequential(\n",
        "            nn.LayerNorm(dim),\n",
        "            nn.Linear(dim, num_classes)\n",
        "        )\n",
        "\n",
        "        self._log_softmax = LogSoftmax(dim=-1)\n",
        "\n",
        "    def forward(self, img):\n",
        "        #print(f'Image shape: {img.shape}')\n",
        "        x = self.to_patch_embedding(img)\n",
        "        # convolutional embedding produces an extra dimension\n",
        "        if len(x.shape) == 4:\n",
        "          x = x.flatten(2)\n",
        "          x = x.transpose(-1, -2)\n",
        "        #print(f'After patch embedding: {x.shape}')\n",
        "        b, n, _ = x.shape\n",
        "\n",
        "        x += self.pos_embedding[:, :n]\n",
        "        #print(f'after pos embedding: {x.shape}')\n",
        "        x = self.dropout(x)\n",
        "        #print(f'Before transformer: {x.shape}')\n",
        "        x = self.transformer(x)\n",
        "        #print(f'After transformer: {x.shape}')\n",
        "\n",
        "        batch_len, sequence_len, hidden_len = x.shape\n",
        "\n",
        "        x = x.reshape(-1, hidden_len)\n",
        "        logits = self.mlp_head(x)\n",
        "        logits = logits.view(batch_len, sequence_len, -1)\n",
        "        logits = self._log_softmax(logits)\n",
        "        logits = logits.permute(1, 0, 2)\n",
        "        \n",
        "        #print(f'After logits: {logits.shape}')\n",
        "        return logits"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NOeG-Q__JmeV"
      },
      "source": [
        "train_loader = torch.utils.data.DataLoader(trainset, batch_size=16, collate_fn=base_collator_with_padding(\"label_indices\"), shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(testset, batch_size=16, collate_fn=base_collator_with_padding(\"label_indices\"), shuffle=True)"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MtvRe1EIHfQZ",
        "outputId": "16dd48fe-6f7e-436a-8944-e1bdbe96e637"
      },
      "source": [
        "#model = CRNN()\n",
        "model = ViT(image_size=(50, 500), patch_size=(50, 5), num_classes=(len(vocab)+1),\n",
        "            depth=6, dim=512, mlp_dim=2048, heads=8, channels=1, \n",
        "            patch_method=\"cnn\", transformer='performer')"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "unable to import cuda code for auto-regressive Performer. will default to the memory inefficient non-cuda version\n",
            "unable to import cuda code for auto-regressive Performer. will default to the memory inefficient non-cuda version\n",
            "unable to import cuda code for auto-regressive Performer. will default to the memory inefficient non-cuda version\n",
            "unable to import cuda code for auto-regressive Performer. will default to the memory inefficient non-cuda version\n",
            "unable to import cuda code for auto-regressive Performer. will default to the memory inefficient non-cuda version\n",
            "unable to import cuda code for auto-regressive Performer. will default to the memory inefficient non-cuda version\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hPoqRvXWP8wo",
        "outputId": "44105cd3-73f1-4db4-ee46-a1c4c7ad9e49"
      },
      "source": [
        "x = torch.randn(1,1,50,500)\n",
        "out = model(x)\n",
        "out.shape"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([100, 1, 80])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ehq1kZAqO3L0"
      },
      "source": [
        "model = model.cuda()"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WIaZQiF9IGKp"
      },
      "source": [
        "# load pre-trained weights\n",
        "if os.path.exists(\"/content/gdrive/MyDrive/PerfViT_IAM.pth\"):\n",
        "  model.load_state_dict(torch.load(\"/content/gdrive/MyDrive/PerfViT_IAM.pth\"))"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zMjOOeSWNYTH"
      },
      "source": [
        "blank_label = len(vocab)"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aDAN-w1QKA-c"
      },
      "source": [
        "criterion = nn.CTCLoss(blank=blank_label, reduction='mean', zero_infinity=True)\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.01)\n",
        "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer=optimizer, patience=5, verbose=True)"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qCiSt23yY436",
        "outputId": "b0ffe050-6634-4ac0-a69a-3bfc29c3894d"
      },
      "source": [
        "print(f\"Model has {count_parameters(model):.2f}M parameters\")"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model has 19.14M parameters\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SHqI3OahjUGc"
      },
      "source": [
        "epochs=25"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yc1hgf5qRzyq"
      },
      "source": [
        "def create_logit_lengths(batch_size, sequence_length):\n",
        "    return torch.full((batch_size,), sequence_length, dtype=torch.int64)"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tmmt4rBkKDPP",
        "outputId": "1420cf6a-6503-4eac-eec3-bb2136228999"
      },
      "source": [
        "# ================================================ TRAINING MODEL ======================================================\n",
        "best_ed = np.inf\n",
        "for epoch in range(epochs):\n",
        "    # ============================================ TRAINING ============================================================\n",
        "    train_correct = 0\n",
        "    train_total = 0\n",
        "    model.train()\n",
        "    train_loss = 0.0\n",
        "    train_ed = 0\n",
        "    train_cc = 0\n",
        "    for data in tqdm(train_loader,\n",
        "                     position=0, leave=True,\n",
        "                     file=sys.stdout, bar_format=\"{l_bar}%s{bar}%s{r_bar}\" % (Fore.GREEN, Fore.RESET)):\n",
        "        tensor_keys = [\"image\", \"label_indices\", \"label_length\"]\n",
        "        images, label_indices, label_lengths = tuple(\n",
        "            data[k].cuda() for k in tensor_keys\n",
        "        )\n",
        "\n",
        "        b, h, w = images.shape\n",
        "        images = images.reshape(b, 1 , h, w)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        y_pred = model(images)\n",
        "\n",
        "        l = create_logit_lengths(y_pred.shape[1], y_pred.shape[0]) \n",
        "        loss = criterion(y_pred, label_indices, l, label_lengths)\n",
        "        \n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        train_loss += loss.item()\n",
        "        \n",
        "        _, max_index = torch.max(y_pred, dim=2)  # max_index.shape == torch.Size([32, 64])\n",
        "        for i in range(b):\n",
        "            raw_prediction = list(max_index[:, i].detach().cpu().numpy())  # len(raw_prediction) == 32\n",
        "            prediction = torch.IntTensor([c for c, _ in groupby(raw_prediction) if c != blank_label])\n",
        "            if len(prediction):\n",
        "              text = [vocab[k] for k in prediction]\n",
        "              train_ed += editdistance.eval(text, data['label_str'][i])\n",
        "            else:\n",
        "              train_ed += len(data['label_str'][i])  # the entire string is missing\n",
        "            train_cc += len(data['label_str'][i])\n",
        "            train_total += 1\n",
        "    print(f'TRAINING. editdistance: {train_ed}/{train_total}={train_ed/train_total:.3f}')\n",
        "    print(f\"[{epoch}] Train loss: {train_loss:.2f}, avg. char count={train_cc/train_total:.3f}\")\n",
        "\n",
        "    scheduler.step(train_loss)\n",
        "\n",
        "    # ============================================ VALIDATION ==========================================================\n",
        "    val_correct = 0\n",
        "    val_total = 0\n",
        "    model.eval()\n",
        "    val_loss = 0.0\n",
        "    val_ed = 0\n",
        "    val_cc = 0\n",
        "    TO_DISPLAY = 10\n",
        "    for data in test_loader:\n",
        "        tensor_keys = [\"image\", \"label_indices\", \"label_length\"]\n",
        "        images, label_indices, label_lengths = tuple(\n",
        "            data[k].cuda() for k in tensor_keys\n",
        "        )\n",
        "\n",
        "        b, h, w = images.shape\n",
        "        images = images.reshape(b, 1 , h, w)\n",
        "        \n",
        "        with torch.set_grad_enabled(False):\n",
        "            y_pred = model(images)\n",
        "        \n",
        "        y_pred = model(images)\n",
        "\n",
        "        l = create_logit_lengths(y_pred.shape[1], y_pred.shape[0]) \n",
        "        loss = criterion(y_pred, label_indices, l, label_lengths)\n",
        "\n",
        "        val_loss += loss.item()\n",
        "\n",
        "        _, max_index = torch.max(y_pred, dim=2)\n",
        "        for i in range(b):\n",
        "            raw_prediction = list(max_index[:, i].detach().cpu().numpy())\n",
        "            prediction = torch.IntTensor([c for c, _ in groupby(raw_prediction) if c != blank_label])\n",
        "            if len(prediction):\n",
        "              text = ''.join([vocab[k] for k in prediction])\n",
        "              val_ed += editdistance.eval(text, data['label_str'][i])\n",
        "            else:\n",
        "              text = ''\n",
        "              val_ed += len(data['label_str'][i])\n",
        "            val_cc += len(data['label_str'][i])\n",
        "            val_total += 1\n",
        "            if val_total < TO_DISPLAY:\n",
        "              print(f\"Output={text}\\t Label={data['label_str'][i]}\")\n",
        "    # save best weights\n",
        "    if val_ed < best_ed:\n",
        "      best_ed = val_ed\n",
        "      print(f\"Best model seen [{best_ed:.2f}], saving weights...\")\n",
        "      torch.save(model.state_dict(), \"/content/gdrive/MyDrive/PerfViT_IAM.pth\")\n",
        "    print(f'TESTING editdistance:  {val_ed}/{val_total} = {val_ed/val_total:.3f}')\n",
        "    print(f\"[{epoch}] Test loss: {val_loss:.2f}, avg char count: {val_cc/val_total:.3f}\")\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|\u001b[32m\u001b[39m| 752/752 [08:18<00:00,  1.51it/s]\n",
            "TRAINING. editdistance: 505507/12032=42.014\n",
            "[0] Train loss: 2212.18, avg. char count=43.230\n",
            "Output=uf!!!bfu!f\t Label=ones ) , is becoming quite an accomplished actress .\n",
            "Output=uu!!!u!h!/\t Label=too long .\n",
            "Output=!!fu!f!uiff!/\t Label=public of the change .\n",
            "Output=u!p!fuff!f!f\t Label=than forty or fifty days after preparation , the\n",
            "Output=p!!f!/\t Label=pro-western centre and south .\n",
            "Output=pf!f!!b!f!u\t Label=of the strontium sulphate is incomplete . Using\n",
            "Output=Ui!\t Label=Table 1 shows the decontamination factors\n",
            "Output=f!!b!f!i!f\t Label=original stand . Only where the issues were\n",
            "Output=Ui!f!!f!fff\t Label=towns , grey , rose-headed mariners clinging\n",
            "Best model seen [54742.00], saving weights...\n",
            "TESTING editdistance:  54742/1321 = 41.440\n",
            "[0] Test loss: 244.36, avg char count: 42.867\n",
            "100%|\u001b[32m\u001b[39m| 752/752 [08:23<00:00,  1.49it/s]\n",
            "TRAINING. editdistance: 505252/12032=41.992\n",
            "[1] Train loss: 2194.72, avg. char count=43.230\n",
            "Output=bf!!p!fb!!b!!uf!f!fe\t Label=over , asked ever so many questions which I had\n",
            "Output=!bb!ifhz!f!f\t Label=At an early stage of the census\n",
            "Output=uf!ffb!fu!!/\t Label=homely and protecting flame .\n",
            "Output=bffp!p!ff!if\t Label=are more effective for the delicate designs used for\n",
            "Output=pffb!!\t Label=Lucia , ' said Vittoria , pointing to the badge on the man's\n",
            "Output=fup!f!!u!uf!u\t Label=Its terms have set the Prime Minister an exacting\n",
            "Output=f!f!u!f!b!fuf\t Label=Each size of hook is made for use with a certain\n",
            "Output=fff!m!b!!b!!f!/\t Label=Yesterday Sir Roy's chief aide , Mr.\n",
            "Output=ui!!uifq!b!f!!bfb!-\t Label=long run . They may be inaccurate ,\n",
            "Best model seen [54597.00], saving weights...\n",
            "TESTING editdistance:  54597/1321 = 41.330\n",
            "[1] Test loss: 240.97, avg char count: 42.867\n",
            "100%|\u001b[32m\u001b[39m| 752/752 [08:17<00:00,  1.51it/s]\n",
            "TRAINING. editdistance: 504553/12032=41.934\n",
            "[2] Train loss: 2192.56, avg. char count=43.230\n",
            "Output=hfb!pf\t Label=get it into your head , son ... people\n",
            "Output=ff!bf!z!b!!z\t Label=encountering this tendency\n",
            "Output=Uffff!\t Label=Progressive party , Dr. Steytler , in Port\n",
            "Output=f!bh!f!!b!b!f!f!ff!/\t Label=who used the system - and used it with power and authority .\n",
            "Output=uf!!b!!bf!!\t Label=if she could . What she had forgotten\n",
            "Output=f!!b!f!b!!!fb\t Label=original stand . Only where the issues were\n",
            "Output=f!b!fb!uuf!f\t Label=much rain and damp , but the tempe-\n",
            "Output=ff!f!p!ff!fuf\t Label=attitude . Now if there 'd been a good old accident ,\n",
            "Output=i!!f!f!fb!ufu!e\t Label=charges of creating disturbances . During the first\n",
            "TESTING editdistance:  54649/1321 = 41.369\n",
            "[2] Test loss: 239.57, avg char count: 42.867\n",
            "100%|\u001b[32m\u001b[39m| 752/752 [08:16<00:00,  1.51it/s]\n",
            "TRAINING. editdistance: 503938/12032=41.883\n",
            "[3] Train loss: 2175.46, avg. char count=43.230\n",
            "Output=f!f!fff!ffff!\t Label=down # unambiguous alternatives to\n",
            "Output=p!ff!ff!f!u!f!uff\t Label=of course ) and for those to have\n",
            "Output=!fub!!f!/\t Label=serve this home of his , in which his heart lay .\n",
            "Output=uifuf!!ff!bf!f!f!hf!\t Label=streets and wet pavements , the school play-\n",
            "Output=i!u!f!fb!!g!g!ff!/\t Label=at the Royal Herbert Hospital , full of war prisoners .\n",
            "Output=U!hhf!!!u\t Label=to go on .\n",
            "Output=f!!ff!uff\t Label=Shouts , and the clatter of feet meant\n",
            "Output=Uf!u!/\t Label=his days as Britain's chief UN dele-\n",
            "Output=!fff!f!f!f!uf!fffu#\t Label=an effective alleviation of his painful\n",
            "Best model seen [54569.00], saving weights...\n",
            "TESTING editdistance:  54569/1321 = 41.309\n",
            "[3] Test loss: 238.28, avg char count: 42.867\n",
            "100%|\u001b[32m\u001b[39m| 752/752 [08:18<00:00,  1.51it/s]\n",
            "TRAINING. editdistance: 503102/12032=41.814\n",
            "[4] Train loss: 2162.00, avg. char count=43.230\n",
            "Output=!h!!bhqf!/\t Label=what may happen ... .\n",
            "Output=i!!ffff\t Label=the ground as well as in midwater and\n",
            "Output=!!f!f!fe\t Label=throughout in terms of the cinema , and again\n",
            "Output=!!!f!uf!f!!\t Label=who is also part-author with Miss Delaney\n",
            "Output=!hu!!f!!uf!/\t Label=had been brought to his notice .\n",
            "Output=!f!b!!!!pz\t Label=doubtful positions , and for a consistent\n",
            "Output=f!h!fe\t Label=Then they stop swimming and are caught . In\n",
            "Output=p!uzfh!ff!f/\t Label=whom Anglesey consulted in May 1834 .\n",
            "Output=u!f!!!!!!h!!/\t Label=too long .\n",
            "TESTING editdistance:  54891/1321 = 41.553\n",
            "[4] Test loss: 235.05, avg char count: 42.867\n",
            "100%|\u001b[32m\u001b[39m| 752/752 [08:25<00:00,  1.49it/s]\n",
            "TRAINING. editdistance: 501569/12032=41.686\n",
            "[5] Train loss: 2149.95, avg. char count=43.230\n",
            "Output=b!b!bh!f!f!i!f!g!/\t Label=about their feeding , the same subtle delicacy of touch ,\n",
            "Output=p!bhf!ufuf!f!f!f!\t Label=one eyebrow . \" Actually she was brunette\n",
            "Output=p!fu!ffh!f!uf!uffh!mfe\t Label=cigarettes worth smoking , these . Most unhealthy , English\n",
            "Output=ui!huf!pf!!!if!u!u!u!gim\t Label=her fan , in passing ; but she did not wait for\n",
            "Output=pg!!!!u!uuf!!!gfh!!/\t Label=information , which held no interest for her :\n",
            "Output=p!!!!ufif!fu!fu!u!gz!/\t Label=on the bridge over the Po , barely forty miles to port .\n",
            "Output=ufuhf!f!z\t Label=exactly down to the taper line ,\n",
            "Output=!fuf!f!u!!f!f!f!\t Label=\" I made it myself , \" Gay tried to speak\n",
            "Output=b!h!!gf!f!f!ubu!zf!f!!f!f\t Label=hunting for furnished rooms , and had given up , when an\n",
            "Best model seen [54077.00], saving weights...\n",
            "TESTING editdistance:  54077/1321 = 40.936\n",
            "[5] Test loss: 235.32, avg char count: 42.867\n",
            "100%|\u001b[32m\u001b[39m| 752/752 [08:29<00:00,  1.48it/s]\n",
            "TRAINING. editdistance: 500449/12032=41.593\n",
            "[6] Train loss: 2124.11, avg. char count=43.230\n",
            "Output=p!uhi!!i!u!uf!f!!u\t Label=native kingdoms in Uganda arrived for talks with\n",
            "Output=ui!u!u!h!!!uifu!uu!e\t Label=is prepared to pay , and the type of\n",
            "Output=ij!!!hu!f!f!f!e\t Label=Graybury is one of Mr. Hewson's most\n",
            "Output=!!!!!!!z!uf!uf!\t Label=Mr. Wilson's offer in mind . Guy Eden writes :\n",
            "Output=b!!hz!!!!!!!!f!!ui!/\t Label=of fins only 0.006 in. ( 0.15 mm. ) thick .\n",
            "Output=p!u!/\t Label=the river road .\n",
            "Output=p!f!ug!!!u!!e\t Label=to revise the course in the light of\n",
            "Output=buu!!!f!!!ufh!u!!f\t Label=mutual . But Laud was no Romanizer . One of his\n",
            "Output=b!iuh!!!uu!fifuu\t Label=as though his son would actually\n",
            "Best model seen [54029.00], saving weights...\n",
            "TESTING editdistance:  54029/1321 = 40.900\n",
            "[6] Test loss: 230.48, avg char count: 42.867\n",
            "100%|\u001b[32m\u001b[39m| 752/752 [08:28<00:00,  1.48it/s]\n",
            "TRAINING. editdistance: 499463/12032=41.511\n",
            "[7] Train loss: 2115.87, avg. char count=43.230\n",
            "Output=U!!f!u!u\t Label=The Minister regards the recent trend\n",
            "Output=!!f!!!g!/\t Label=not have to exert herself .\n",
            "Output=!h!!!!!!!#\t Label=that chap , Hewitt , too . Leave it to me . '\n",
            "Output=!hu!!g!uu!!!!!ff\t Label=to find , if possible , Hubert and his\n",
            "Output=i!!!fi!!!fe\t Label=diligently unto my commandments , which I command\n",
            "Output=\t Label=He needed her . She would find\n",
            "Output=!!!mum!!!u!u!\t Label=learns sex is something sordid , and when she\n",
            "Output=p!fg\t Label=as soon as he had spoken a few\n",
            "Output=!!u!!g!e\t Label=it out with Piers when a reasonable\n",
            "TESTING editdistance:  54712/1321 = 41.417\n",
            "[7] Test loss: 228.68, avg char count: 42.867\n",
            "100%|\u001b[32m\u001b[39m| 752/752 [08:24<00:00,  1.49it/s]\n",
            "TRAINING. editdistance: 498848/12032=41.460\n",
            "[8] Train loss: 2088.38, avg. char count=43.230\n",
            "Output=uhhuu\t Label=and other major questions , Mr. Jack Cooper\n",
            "Output=b!uu!uf!!!u!jhif\t Label=a new Conservative booklet called The Record Speaks\n",
            "Output=u!!u!!!!!hh!t\t Label=Market , and the kite-flying on Spain\n",
            "Output=Ui!uui!u!!ig!f!if\t Label=The next female fatality occurred eight years later ,\n",
            "Output=i!ghuf!u!i!!!!u!f\t Label=A glance at the gauge marks at the bottom\n",
            "Output=pu!ui!hu!hu!/\t Label=about the nuptial arrangements .\n",
            "Output=u!!\t Label=the time of Victoria this gentle craft was\n",
            "Output=uuhf!!\t Label=not with that great little Irish bar on\n",
            "Output=ui!!!!!!uh!uiu!f\t Label=first public acts was a hard-hitting battle with\n",
            "TESTING editdistance:  54317/1321 = 41.118\n",
            "[8] Test loss: 226.56, avg char count: 42.867\n",
            "100%|\u001b[32m\u001b[39m| 752/752 [08:22<00:00,  1.50it/s]\n",
            "TRAINING. editdistance: 498842/12032=41.460\n",
            "[9] Train loss: 2068.24, avg. char count=43.230\n",
            "Output=p!!ug!!!u!!\t Label=to revise the course in the light of\n",
            "Output=uf!!ughh!u!qff\t Label=turn . By comparing personal appearances\n",
            "Output=p!!u!u!u!zh!u\t Label=come across human Shamirs and they leave\n",
            "Output=i!hqgm!uj!u!!i!!ujif\t Label=her packages . This sister was able to establish\n",
            "Output=b!i!!uh!!u!!!i!u!uuf\t Label=was developed into quite an elaborate and distinctive\n",
            "Output=N!h!!u!u!fu!!!uf!!!ut\t Label=6impasse which always resulted , and in the\n",
            "Output=b!uuum!!!!!!!!ium\t Label=he could collect his wits to reply to this , there was a bustle\n",
            "Output=u!!!!!!/\t Label=Government's frequent appeals to the electorate .\n",
            "Output=uhz!!i!u!/\t Label=though somewhat dim picture .\n",
            "TESTING editdistance:  54313/1321 = 41.115\n",
            "[9] Test loss: 224.64, avg char count: 42.867\n",
            "100%|\u001b[32m\u001b[39m| 752/752 [08:21<00:00,  1.50it/s]\n",
            "TRAINING. editdistance: 498188/12032=41.405\n",
            "[10] Train loss: 2058.00, avg. char count=43.230\n",
            "Output=b!i!u!uf!!u!u!h!q!!-\t Label=of Radicalism , & then God knows what may happen ... .\n",
            "Output=bu!!u!u!!u!ui!hu!!/\t Label=and Sir Frederick Stoven , but with their perfect con-\n",
            "Output=!!!!!u!fui!!f!/\t Label=but even so it may be better than a meaningless abstraction .\n",
            "Output=upu!g!i!u!u!u!u!ue\t Label=Sometimes she took Harry around with her , but\n",
            "Output=hi!u!gu!uu!u!u!!uj!h!/\t Label=for the people the board will earn their good will .\n",
            "Output=u!u!!!u!\t Label=great chance that should be grasped .\n",
            "Output=Ui!!ui!u!i!u!uu!!ft\t Label=Their offering last night differed little\n",
            "Output=iue!uu!u!i!!u!uif\t Label=demonstrated outside the British-owned Kingsway\n",
            "Output=uf!u!u!!!hf!!!!!/\t Label=flying she might be in danger . \" \" That 's so .\n",
            "Best model seen [53808.00], saving weights...\n",
            "TESTING editdistance:  53808/1321 = 40.733\n",
            "[10] Test loss: 225.51, avg char count: 42.867\n",
            "100%|\u001b[32m\u001b[39m| 752/752 [08:22<00:00,  1.50it/s]\n",
            "TRAINING. editdistance: 498106/12032=41.398\n",
            "[11] Train loss: 2051.43, avg. char count=43.230\n",
            "Output=u!uj!i!!h!!iu!ui!!!uf\t Label=The figures for Corby and Peterlee ( where the\n",
            "Output=i!!!!g!uh!!u!\t Label=the peace and for inciting a breach\n",
            "Output=p!!!!!!!u!!!!e\t Label=ster at her own home . Each child had a\n",
            "Output=qf!q!u!!uuiu!uu!u!zzz\t Label=place agree with me better than Naples . The journey\n",
            "Output=ui!!!!g!uf!!u!e\t Label=to pass the time of day \" ; Supporters had\n",
            "Output=pz!u!!u!!!h!\t Label=quisitively . As is the case in Fanny her\n",
            "Output=i!f!!!g!u!!h!huf\t Label=still be free in families receiving regular\n",
            "Output=!u!!!!u\t Label=judge always had on the table at dinner , he\n",
            "Output=i!f!ufmj!!uu!!ue\t Label=the same , thermoelectric contributions to the\n",
            "TESTING editdistance:  54008/1321 = 40.884\n",
            "[11] Test loss: 224.51, avg char count: 42.867\n",
            "100%|\u001b[32m\u001b[39m| 752/752 [08:24<00:00,  1.49it/s]\n",
            "TRAINING. editdistance: 497299/12032=41.331\n",
            "[12] Train loss: 2036.75, avg. char count=43.230\n",
            "Output=pu!!g!!uu!!u!g!/\t Label=back to England , and returned to Rome for the\n",
            "Output=ui!ff!h!!e\t Label=the fourteenth century . \"\n",
            "Output=up!!m!f!h!gu!!!!!u\t Label=the cookie to make you a fresh lot ? ' ' I 'd rather\n",
            "Output=!!\t Label=huh ? \"\n",
            "Output=uh!!u!uu!!!u!!\t Label=meeting in Paris between M. Couve de Murville , French\n",
            "Output=!h!!!u!!!\t Label=thought of a fire ... .\n",
            "Output=q!ug!ui!!!!ff\t Label=say this . I 'd like to live in America\n",
            "Output=uh!u!u!h!!!!\t Label=The journey has been against me , as there has\n",
            "Output=i!!!uu!!h!!huf\t Label=better appearance . Later , on many a sunny Sunday\n",
            "TESTING editdistance:  54050/1321 = 40.916\n",
            "[12] Test loss: 221.65, avg char count: 42.867\n",
            "100%|\u001b[32m\u001b[39m| 752/752 [08:20<00:00,  1.50it/s]\n",
            "TRAINING. editdistance: 496376/12032=41.255\n",
            "[13] Train loss: 2014.72, avg. char count=43.230\n",
            "Output=!!g!!u!gug!!gf\t Label=He rose from his breakfast-nook bench\n",
            "Output=!u!-hu-j!/\t Label=America's balance of payments position .\n",
            "Output=ui!u!h!u!!!!z!/\t Label=the atmosphere of a city .\n",
            "Output=pu!!!h!!!u!!!\t Label=cold and uneasy , unable to account\n",
            "Output=pz!ug!!uju!!h!-\t Label=shops for every thousand people ,\n",
            "Output=j!m!uu!uh!!h!\t Label=it reaches them . They move away before\n",
            "Output=u!g!u!!!uh!u!!u!phg\t Label=produce fashion articles as elegant as those of\n",
            "Output=ui!g!g!u!!u!!!!\t Label=the first of these is due in 1963 . Meanwhile , each\n",
            "Output=!u!u!h!hi!!u!u!!\t Label=destroy the whole population of Britain in\n",
            "TESTING editdistance:  54149/1321 = 40.991\n",
            "[13] Test loss: 220.44, avg char count: 42.867\n",
            "100%|\u001b[32m\u001b[39m| 752/752 [08:17<00:00,  1.51it/s]\n",
            "TRAINING. editdistance: 496071/12032=41.229\n",
            "[14] Train loss: 2010.68, avg. char count=43.230\n",
            "Output=ui!u!ujuh!uf!uufe\t Label=the stop-watch manufacturing methods that\n",
            "Output=upu!!u!!uu!!!!!!!h/\t Label=burdens of Egypt . ( 2 ) I will rid you of their bondage .\n",
            "Output=!!u!u!u!\t Label=There was a somewhat shocked atmosphere in\n",
            "Output=pg!!!!u!ui!!uuh!u!/\t Label=information , which held no interest for her :\n",
            "Output=ui!u!u!hqu!!humzh\t Label=to have been guests at yesterday's\n",
            "Output=\t Label=closed session to discuss Weaver's appointment .\n",
            "Output=u!!g!!i!!t\t Label=original stand . Only where the issues were\n",
            "Output=ui!uu!!!u!gu!!h!u!!uuf\t Label=told Arthur , ' to find this place agree with me better\n",
            "Output=i!ui!!ui!uj!uig!u!!zf\t Label=Motion there was , but motion without event - except\n",
            "TESTING editdistance:  54149/1321 = 40.991\n",
            "[14] Test loss: 220.11, avg char count: 42.867\n",
            "100%|\u001b[32m\u001b[39m| 752/752 [08:24<00:00,  1.49it/s]\n",
            "TRAINING. editdistance: 495629/12032=41.193\n",
            "[15] Train loss: 2000.35, avg. char count=43.230\n",
            "Output=ube!u!!u!hu!!ugf/\t Label=rushed out to Rhodesia . Overnight , minor African\n",
            "Output=p!u!!!!!h!\t Label=signor , ' she whispered . ' I am the Orsini . My word is\n",
            "Output=!u!-j!/\t Label=America's balance of payments position .\n",
            "Output=u!e!!iqh!!!f-\t Label=The heli-hopping Duke of Edinburgh ,\n",
            "Output=iuh!!!i!!u!uufe\t Label=brandy owner's solo swish on his anecdotal\n",
            "Output=u!!!g!u!u!ufzz\t Label=On the eve of August Bank Holiday\n",
            "Output=bu!!u!!uih!!uhz\t Label=workers in the same industry - along\n",
            "Output=u!!gz!!!!!!!!f\t Label=I slept soundly , and much later than I should . It\n",
            "Output=p!!g!u!g!!!uf\t Label=of course ) and for those to have\n",
            "TESTING editdistance:  54239/1321 = 41.059\n",
            "[15] Test loss: 217.88, avg char count: 42.867\n",
            "100%|\u001b[32m\u001b[39m| 752/752 [08:30<00:00,  1.47it/s]\n",
            "TRAINING. editdistance: 495071/12032=41.146\n",
            "[16] Train loss: 1983.04, avg. char count=43.230\n",
            "Output=z!!u!!!u\t Label=inevitability which left its central character\n",
            "Output=u!!u!u!!u!u!hg!!/\t Label=and Sir Frederick Stoven , but with their perfect con-\n",
            "Output=uf!!!!uu!ugfu!guif\t Label=Workers' Educational Association , submitted\n",
            "Output=phe!hu!u!!u!u!!hie\t Label=original question and answer and this is quoted\n",
            "Output=qi!h!uuu!!!u!!/\t Label=for by that curious body Moral Re-Armament .\n",
            "Output=Uiu!!i!!!h!!\t Label=Instead Mr. Macmillan will rely on a\n",
            "Output=uiu!f!!!u!h!g!jume\t Label=that Labour should not take any steps which would\n",
            "Output=!!!ug!u!!fe\t Label=\" That cannot continue without either development\n",
            "Output=u!u!!!!h!!q!h/\t Label=time they docked at Belleray . And though Guy ,\n",
            "TESTING editdistance:  54177/1321 = 41.012\n",
            "[16] Test loss: 216.23, avg char count: 42.867\n",
            "100%|\u001b[32m\u001b[39m| 752/752 [08:30<00:00,  1.47it/s]\n",
            "TRAINING. editdistance: 494521/12032=41.100\n",
            "[17] Train loss: 1986.98, avg. char count=43.230\n",
            "Output=fzemff!guie!fuff\t Label=Conservatives protested when\n",
            "Output=bf!!!u!!!-!!he\t Label=throughout in terms of the cinema , and again\n",
            "Output=b!!qj!uu!eu!!uf!!!f!/\t Label=at a piece called \" Piccadilly \" ( Polydor ) . I find it cute .\n",
            "Output=e!e!!uf!hg!uu!g!uf\t Label=R. Joshua b. Levi . The proof text for the\n",
            "Output=b!!!!g!!hu!q!/\t Label=water cooled flange G .\n",
            "Output=uu!u!i!h!/\t Label=part of the story .\n",
            "Output=!f!!!h!u!h!i!u!u!!!g\t Label=\" He is not going to agree to be bound over . That will\n",
            "Output=uiuuh!u!u!g!uhi!g!!uze\t Label=Suddenly he crouched forward . \" Broughtons , if I thought\n",
            "Output=ui!mu!!!if!gf!!i!f\t Label=A certificate ) , Peter Brook's film made\n",
            "Best model seen [53702.00], saving weights...\n",
            "TESTING editdistance:  53702/1321 = 40.653\n",
            "[17] Test loss: 216.19, avg char count: 42.867\n",
            "100%|\u001b[32m\u001b[39m| 752/752 [08:27<00:00,  1.48it/s]\n",
            "TRAINING. editdistance: 493734/12032=41.035\n",
            "[18] Train loss: 1968.28, avg. char count=43.230\n",
            "Output=i!!!uuu!uuu!uu!u!uie\t Label=chiefly to provide sufficient support for the flat plates to withstand\n",
            "Output=ui!gu!uui!uj!uq!uugz\t Label=have joined this train by taking\n",
            "Output=phh!!uu-!!!u!g!u!!je\t Label=momentary shudder , or idea of destruction , a thrill\n",
            "Output=gu/\t Label=she had tea with her other sister , and then\n",
            "Output=uie!!!u!-!u!!!!!if\t Label=but the bank would give me a loan , I 'm\n",
            "Output=b!!u!!j!hu!!u/\t Label=of them Left-wing # sympathisers .\n",
            "Output=cb!eu!!u!u!ggu!u!!h!!!\t Label=no matter how bad it felt , the fire you know , or a\n",
            "Output=U!!u!g!gi!!i!ju!/\t Label=in the preparation of stimulants for the palate ,\n",
            "Output=ui!!uzu!he!u!!!!ui\t Label=the Scarborough conference decisions did not , in his\n",
            "Best model seen [53687.00], saving weights...\n",
            "TESTING editdistance:  53687/1321 = 40.641\n",
            "[18] Test loss: 215.38, avg char count: 42.867\n",
            "100%|\u001b[32m\u001b[39m| 752/752 [08:24<00:00,  1.49it/s]\n",
            "TRAINING. editdistance: 492918/12032=40.967\n",
            "[19] Train loss: 1960.68, avg. char count=43.230\n",
            "Output=uif!u!ug!!u!!q!gu!\t Label=She said icily , \" As you pride yourself on\n",
            "Output=qe!!!!uhmu!-\t Label=preyed upon his thoughts .\n",
            "Output=!!qu!uu!ufu!uz!u!-!uuus\t Label=A new question asked about housing tenure , whether\n",
            "Output=ihh!i!uu!!u!!!!!u\t Label=staggered . Some of it is inevitable , and we do not want to\n",
            "Output=uu!e!u!u!!u!u!ugh!\t Label=streets and wet pavements , the school play-\n",
            "Output=gpf!uuu!u!uufe\t Label=Government was to denounce the United\n",
            "Output=bq!u!uihuu!i!u!u!uuu\t Label=may have thought I had become unbalanced\n",
            "Output=u!!u!g!gi!!i!ju!/\t Label=in the preparation of stimulants for the palate ,\n",
            "Output=ui!h!z!!u!u!f\t Label=begun . Some plain tapered legs have\n",
            "Best model seen [53664.00], saving weights...\n",
            "TESTING editdistance:  53664/1321 = 40.624\n",
            "[19] Test loss: 213.97, avg char count: 42.867\n",
            "100%|\u001b[32m\u001b[39m| 752/752 [08:27<00:00,  1.48it/s]\n",
            "TRAINING. editdistance: 492789/12032=40.957\n",
            "[20] Train loss: 1948.79, avg. char count=43.230\n",
            "Output=uuuuuu\t Label=a woman's . It belonged to a Madame\n",
            "Output=buu-!u-!u!u!uj!!!g!ug\t Label=control . Nato , far from being a means of controlling\n",
            "Output=Uimuuz!!!e\t Label=For short ones a smoothing plane can be used .\n",
            "Output=Nfuu!!ff!!!o!uff\t Label=He smiled at his own joke .\n",
            "Output=jmm!!g!!uu!!iu\t Label=installation of a power tool . As an elementary\n",
            "Output=jofoeu!ui\t Label=Lucia , ' said Vittoria , pointing to the badge on the man's\n",
            "Output=uu!!u!!u!uj\t Label=confessed everything . Her fiance*?2\n",
            "Output=!g!!!uh!u!u!\t Label=sense of effort , in persuading her little world to\n",
            "Output=fmuu!!uuuuu-!!!!-!uuu!-\t Label=with a theodolite , six surveyors , a ball ;\n",
            "TESTING editdistance:  53726/1321 = 40.671\n",
            "[20] Test loss: 224.53, avg char count: 42.867\n",
            "100%|\u001b[32m\u001b[39m| 752/752 [08:27<00:00,  1.48it/s]\n",
            "TRAINING. editdistance: 491733/12032=40.869\n",
            "[21] Train loss: 1923.02, avg. char count=43.230\n",
            "Output=u!!\t Label=quarter-hour intervals , regular as clockwork ?\n",
            "Output=u\t Label=both at midnight . \" They might have been\n",
            "Output=!u!!u!/\t Label=In no other conquered country , not even\n",
            "Output=u!!\t Label=sea , blue as a new school exercise\n",
            "Output=\t Label=Mr. William Lucas ( Morris ) is always\n",
            "Output=U\t Label=is a pleasing , fine looking young man &\n",
            "Output=u!!\t Label=praying mantis satisfies its voracity by\n",
            "Output=u\t Label=They think there is something\n",
            "Output=!!!!!\t Label=ago to hear of a school who tried a six-\n",
            "TESTING editdistance:  56168/1321 = 42.519\n",
            "[21] Test loss: 291.34, avg char count: 42.867\n",
            " 20%|\u001b[32m        \u001b[39m| 154/752 [01:43<06:42,  1.49it/s]"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QfsgYTF6piFD"
      },
      "source": [
        "torch.save(model.state_dict(), \"/content/gdrive/MyDrive/PerfViT_IAM.pth\")"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SxHPRqeUOGCi",
        "outputId": "28c866da-5197-4c75-f462-77901fd3ebb2"
      },
      "source": [
        "data['image'].shape"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(50, 500)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C8_TGWeOg9LY"
      },
      "source": [
        "count=0\n",
        "COUNT=40\n",
        "for x_val, y_val in val_loader:\n",
        "    batch_size = x_val.shape[0]\n",
        "    # x_val = x_val.view(x_val.shape[0], 1, x_val.shape[2], -1)\n",
        "    t, l = encoder.encode(y_val)\n",
        "\n",
        "    with torch.set_grad_enabled(False):\n",
        "        y_pred = model(x_val.cuda())\n",
        "\n",
        "    y_pred = y_pred.permute(1, 0, 2)\n",
        "    _, max_index = torch.max(y_pred, dim=2)\n",
        "    for i in range(batch_size):\n",
        "        raw_prediction = list(max_index[:, i].detach().cpu().numpy())\n",
        "        prediction = torch.IntTensor([c for c, _ in groupby(raw_prediction) if c != blank_label])\n",
        "        try:\n",
        "          if len(prediction):\n",
        "            text = ''.join([vocab[k] for k in prediction])\n",
        "            print(f\"Output={text},\\t Label={y_val[i]}\")\n",
        "        except IndexError:\n",
        "          pass\n",
        "        count += 1\n",
        "    if count > COUNT:\n",
        "      break"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xc8zIYjNK7Tl"
      },
      "source": [
        "from einops.layers.torch import Rearrange"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E1Xc038jMEqj"
      },
      "source": [
        "img = torch.randn(1,1,32,512)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nYmLPTg-LD35"
      },
      "source": [
        "R = Rearrange('b c (h p1) (w p2) -> b (h w) (p1 p2 c)', p1 = 32, p2 = 8)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fJcYQ_2pLcHM",
        "outputId": "29bc8771-7f80-443f-d0fe-3658053431f1"
      },
      "source": [
        "r = R(img)\n",
        "r.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 64, 256])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FPH9IKpiPY--",
        "outputId": "fd05e415-3e07-4b3c-dba1-7e420d8a6c08"
      },
      "source": [
        "transformer = Performer(\n",
        "    dim=512,\n",
        "    depth=1,\n",
        "    heads=8,\n",
        "    dim_head=64,\n",
        "    causal=True\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "unable to import cuda code for auto-regressive Performer. will default to the memory inefficient non-cuda version\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RhUC8ZpNgadx"
      },
      "source": [
        "model = ViT(\n",
        "    image_size=512,\n",
        "    patch_size=8,\n",
        "    num_classes=11,\n",
        "    dim=512,\n",
        "    channels=1,\n",
        "    transformer=transformer,\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QWToGENDhFfk",
        "outputId": "7eb8e396-1bba-4fa8-a047-4110ab7c0af6"
      },
      "source": [
        "model"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ViT(\n",
              "  (to_patch_embedding): Sequential(\n",
              "    (0): Rearrange('b c (h p1) (w p2) -> b (h w) (p1 p2 c)', p1=8, p2=8)\n",
              "    (1): Linear(in_features=64, out_features=512, bias=True)\n",
              "  )\n",
              "  (transformer): Performer(\n",
              "    (net): SequentialSequence(\n",
              "      (layers): ModuleList(\n",
              "        (0): ModuleList(\n",
              "          (0): PreLayerNorm(\n",
              "            (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "            (fn): SelfAttention(\n",
              "              (fast_attention): FastAttention(\n",
              "                (kernel_fn): ReLU()\n",
              "              )\n",
              "              (to_q): Linear(in_features=512, out_features=512, bias=True)\n",
              "              (to_k): Linear(in_features=512, out_features=512, bias=True)\n",
              "              (to_v): Linear(in_features=512, out_features=512, bias=True)\n",
              "              (to_out): Linear(in_features=512, out_features=512, bias=True)\n",
              "              (dropout): Dropout(p=0.0, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (1): PreLayerNorm(\n",
              "            (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "            (fn): Chunk(\n",
              "              (fn): FeedForward(\n",
              "                (w1): Linear(in_features=512, out_features=2048, bias=True)\n",
              "                (act): GELU()\n",
              "                (dropout): Dropout(p=0.0, inplace=False)\n",
              "                (w2): Linear(in_features=2048, out_features=512, bias=True)\n",
              "              )\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (proj_updater): ProjectionUpdater(\n",
              "      (instance): SequentialSequence(\n",
              "        (layers): ModuleList(\n",
              "          (0): ModuleList(\n",
              "            (0): PreLayerNorm(\n",
              "              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "              (fn): SelfAttention(\n",
              "                (fast_attention): FastAttention(\n",
              "                  (kernel_fn): ReLU()\n",
              "                )\n",
              "                (to_q): Linear(in_features=512, out_features=512, bias=True)\n",
              "                (to_k): Linear(in_features=512, out_features=512, bias=True)\n",
              "                (to_v): Linear(in_features=512, out_features=512, bias=True)\n",
              "                (to_out): Linear(in_features=512, out_features=512, bias=True)\n",
              "                (dropout): Dropout(p=0.0, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (1): PreLayerNorm(\n",
              "              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "              (fn): Chunk(\n",
              "                (fn): FeedForward(\n",
              "                  (w1): Linear(in_features=512, out_features=2048, bias=True)\n",
              "                  (act): GELU()\n",
              "                  (dropout): Dropout(p=0.0, inplace=False)\n",
              "                  (w2): Linear(in_features=2048, out_features=512, bias=True)\n",
              "                )\n",
              "              )\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (to_latent): Identity()\n",
              "  (mlp_head): Sequential(\n",
              "    (0): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "    (1): Linear(in_features=512, out_features=11, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ectw_Xg4P1ki"
      },
      "source": [
        "x = torch.randn(1, 16, 32)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 232
        },
        "id": "j_w4SsI7VYRx",
        "outputId": "d78868a3-3281-4782-955d-a49dc32be5e1"
      },
      "source": [
        "plt.imshow(x.squeeze(0), cmap='gray')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7faec1a93690>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b0yhZqOSP9SO",
        "outputId": "1029b3fc-8736-4560-fa1f-583bfbe7905b"
      },
      "source": [
        "out = model(x.unsqueeze(0))\n",
        "out.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 11])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8PRIMaTXVmJg",
        "outputId": "27656d29-1b57-44d9-fd63-a33463364afd"
      },
      "source": [
        "out"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 1.8996, -0.0451,  0.5881, -0.6383, -0.5154, -0.7162, -0.1623,  0.5851,\n",
              "         -0.4277,  0.7611,  0.6347]], grad_fn=<AddmmBackward>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wb2_WdTIP_CH"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7m9w4VzoPjDt"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}